---
title: "Boxture Datasets"
author: "Johnny Cash"
date: "09/14/2014"
output:
  html_document
---

We are going to work with `Boxture dataset`. It comes from Time:Matters company and because data are/should stay private, we **are not** going to publish them. However, we are going to use them to show/learn R.

Our main dataset is XML file, called `Shipments.xml`. As the name already says, we are going to deal with customers shipments from A to B and subsequent its information. 

# Begin

Let's begin with importing these data into R. First, we load `XML library`. 
Then load a custom R function we may need to use later and at last we assign our parsed XML data to shipments variable. 

```{r}
library(XML)
shipments <- "Shipments.xml"
```


## 2 Functions = 2 Speed differences

As for every "problem" there are multiple solutions. Here, we are talking about speed namely how fast can we load all of the data (btw. it's 5 MB large file) into R. 
The answer is that it depends on the functions we use. 

If you want to leverage some speed improvements, you may use this snipped instead. We are NOT going to use it. 

```{r eval=FALSE}
library(XML)
source("xmlFaster.R")
shipments <- xmlParse("Shipments.xml")
data <- xmlToDF(shipments,xpath = "/TABLE/BOXTURE_SHIPMENTS") ## convert XML to dataframe 'data'
```


### xmlToDataFrame 

Through out the whole document I am going to use `xmlToDataFrame` function which comes already with `XML package`.
When I am talking about speed, R and our data, why not to try to measure it, right? 

```{r}
system.time(data <- xmlToDataFrame(shipments)) ## not only we will get execution time, but also we will get "data" dataframe
```

I got something about 30 second. A very long time. But with that other function there is no so much better performance.

### Custom Function based on Hopstat.Wordpress.com

Taken from http://hopstat.wordpress.com/2014/01/14/faster-xml-conversion-to-data-frames/

```{r eval=FALSE}
# Requires to have already xmlParsed data !!! Therefore use xmlParse("Shipments.xml")
system.time(data2 <- xmlToDF(shipments,xpath = "/TABLE/BOXTURE_SHIPMENTS" ))
```

Here I don't see any big improvements. Still similar +- 25 second. The deal is that with larger datasets, you should see far more better performance. Not exponential anymore :)

## Analysis
Let's view our data first - just as an example of what we are going to deal with. We could also use `View(data)` or `head(data)` but because dataset contains over 1000 rows and has many columns, let's only see first row.

```{r}
nrow(data)
ncol(data)
```
Good we have 2665 rows with 43 columns. That's a lot of information just about one shipment. :) The more the better.

```{r fig.width=120, out.width=120}
data[1,] 
```

OK, starting here we already go deeper into the data :) With `names` function we examinate our header names (column names/titles).

```{r}
names(data)
```

Now let's look on some columns and data they can take. 

```{r}
summary(data$State)
```

Ok, so we can have 5 different statuses of each shipment. Names are self-explanatory, I think. Out of those 273 which dont have any status, I can say that in the dataset we do have shipments which come from different "systems". Therefore, some of them don't have any. 
```{r}
summary(data$PaymenType)
```

We also have 2 different kinds of payment types. `KK` means Credit card and `R` means Invoice.


























